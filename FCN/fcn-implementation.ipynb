{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2118595,"sourceType":"datasetVersion","datasetId":1271215}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nfrom torchvision import models\nfrom torchvision.models.vgg import VGG\nfrom PIL import Image\nimport numpy as np\nimport os\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T01:10:35.293841Z","iopub.execute_input":"2026-01-03T01:10:35.294043Z","iopub.status.idle":"2026-01-03T01:10:44.208209Z","shell.execute_reply.started":"2026-01-03T01:10:35.294021Z","shell.execute_reply":"2026-01-03T01:10:44.207617Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Dataset Class","metadata":{}},{"cell_type":"code","source":"# VOC2012 Dataset Class\nclass VOCSegmentation(Dataset):\n    def __init__(self, root, split='train', transform=None, target_transform=None):\n        \"\"\"\n        Args:\n            root: /kaggle/input/pascal-voc-2012-dataset/VOC2012_train_val/VOC2012_train_val\n            split: 'train', 'val', or 'trainval'\n            transform: Transform for input images\n            target_transform: Transform for segmentation masks\n        \"\"\"\n        self.root = root\n        self.split = split\n        self.transform = transform\n        self.target_transform = target_transform\n        \n        # Read image list\n        split_file = os.path.join(root, 'ImageSets', 'Segmentation', f'{split}.txt')\n        with open(split_file, 'r') as f:\n            self.images = [x.strip() for x in f.readlines()]\n        \n        self.img_dir = os.path.join(root, 'JPEGImages')\n        self.mask_dir = os.path.join(root, 'SegmentationClass')\n    \n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, idx):\n        img_name = self.images[idx]\n        \n        # Load image\n        img_path = os.path.join(self.img_dir, f'{img_name}.jpg')\n        image = Image.open(img_path).convert('RGB')\n        \n        # Load mask\n        mask_path = os.path.join(self.mask_dir, f'{img_name}.png')\n        mask = Image.open(mask_path)\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        if self.target_transform:\n            mask = self.target_transform(mask)\n        else:\n            mask = torch.from_numpy(np.array(mask)).long()\n        \n        return image, mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T01:10:44.209757Z","iopub.execute_input":"2026-01-03T01:10:44.210124Z","iopub.status.idle":"2026-01-03T01:10:44.218687Z","shell.execute_reply.started":"2026-01-03T01:10:44.210100Z","shell.execute_reply":"2026-01-03T01:10:44.218002Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"ROOT = \"/kaggle/input/pascal-voc-2012-dataset/VOC2012_train_val/VOC2012_train_val\"\n\ntrain_ds = VOCSegmentation(root=ROOT, split=\"train\")\nval_ds = VOCSegmentation(root=ROOT, split=\"val\")\ntrainval_ds = VOCSegmentation(root=ROOT, split=\"trainval\")\n\nprint(\"Train:\", len(train_ds))\nprint(\"Val:\", len(val_ds))\nprint(\"Train+Val:\", len(trainval_ds))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T01:10:44.219721Z","iopub.execute_input":"2026-01-03T01:10:44.220040Z","iopub.status.idle":"2026-01-03T01:10:44.243620Z","shell.execute_reply.started":"2026-01-03T01:10:44.220007Z","shell.execute_reply":"2026-01-03T01:10:44.243043Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'/kaggle/input/pascal-voc-2012-dataset/VOC2012_train_val/VOC2012_train_val'"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## VGGNet with intermediate outputs","metadata":{}},{"cell_type":"code","source":"class VGGNet(VGG):\n    def __init__(self, pretrained=True, model='vgg16', requires_grad=True, remove_fc=True):\n        super().__init__(make_layers(cfg[model]))\n        self.ranges = ranges[model]\n\n        if pretrained:\n            exec(\"self.load_state_dict(models.%s(pretrained=True).state_dict())\" % model)\n\n        if not requires_grad:\n            for param in super().parameters():\n                param.requires_grad = False\n\n        if remove_fc:\n            del self.classifier\n\n    def forward(self, x):\n        output = {}\n        \n        # Get output after each maxpool layer\n        for idx in range(len(self.ranges)):\n            for layer in range(self.ranges[idx][0], self.ranges[idx][1]):\n                x = self.features[layer](x)\n            output[\"x%d\" % (idx + 1)] = x\n\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T01:10:44.244426Z","iopub.execute_input":"2026-01-03T01:10:44.244733Z","iopub.status.idle":"2026-01-03T01:10:44.257807Z","shell.execute_reply.started":"2026-01-03T01:10:44.244691Z","shell.execute_reply":"2026-01-03T01:10:44.257236Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# different version of vggnet\nranges = {\n    'vgg11': ((0, 3), (3, 6),  (6, 11),  (11, 16), (16, 21)),\n    'vgg13': ((0, 5), (5, 10), (10, 15), (15, 20), (20, 25)),\n    'vgg16': ((0, 5), (5, 10), (10, 17), (17, 24), (24, 31)),\n    'vgg19': ((0, 5), (5, 10), (10, 19), (19, 28), (28, 37))\n}\n\ncfg = {\n    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T01:10:44.258563Z","iopub.execute_input":"2026-01-03T01:10:44.258962Z","iopub.status.idle":"2026-01-03T01:10:44.276158Z","shell.execute_reply.started":"2026-01-03T01:10:44.258939Z","shell.execute_reply":"2026-01-03T01:10:44.275669Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def make_layers(cfg, batch_norm=False):\n    layers = []\n    in_channels = 3\n    for v in cfg:\n        if v == 'M':\n            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n        else:\n            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n            if batch_norm:\n                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n            else:\n                layers += [conv2d, nn.ReLU(inplace=True)]\n            in_channels = v\n    return nn.Sequential(*layers)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T01:10:44.277051Z","iopub.execute_input":"2026-01-03T01:10:44.277269Z","iopub.status.idle":"2026-01-03T01:10:44.291344Z","shell.execute_reply.started":"2026-01-03T01:10:44.277250Z","shell.execute_reply":"2026-01-03T01:10:44.290796Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## FCN Architecture","metadata":{}},{"cell_type":"code","source":"# FCN32s - No skip connections\nclass FCN32s(nn.Module):\n    def __init__(self, pretrained_net, n_class):\n        super().__init__()\n        self.n_class = n_class\n        self.pretrained_net = pretrained_net\n        self.relu = nn.ReLU(inplace=True)\n        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n        self.bn1 = nn.BatchNorm2d(512)\n        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n        self.bn2 = nn.BatchNorm2d(256)\n        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n        self.bn3 = nn.BatchNorm2d(128)\n        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n        self.bn4 = nn.BatchNorm2d(64)\n        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n        self.bn5 = nn.BatchNorm2d(32)\n        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n\n    def forward(self, x):\n        output = self.pretrained_net(x)\n        x5 = output['x5']  # size=(N, 512, x.H/32, x.W/32)\n\n        score = self.bn1(self.relu(self.deconv1(x5)))     # size=(N, 512, x.H/16, x.W/16)\n        score = self.bn2(self.relu(self.deconv2(score)))  # size=(N, 256, x.H/8, x.W/8)\n        score = self.bn3(self.relu(self.deconv3(score)))  # size=(N, 128, x.H/4, x.W/4)\n        score = self.bn4(self.relu(self.deconv4(score)))  # size=(N, 64, x.H/2, x.W/2)\n        score = self.bn5(self.relu(self.deconv5(score)))  # size=(N, 32, x.H, x.W)\n        score = self.classifier(score)                    # size=(N, n_class, x.H/1, x.W/1)\n\n        return score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T01:10:44.292804Z","iopub.execute_input":"2026-01-03T01:10:44.293053Z","iopub.status.idle":"2026-01-03T01:10:44.308477Z","shell.execute_reply.started":"2026-01-03T01:10:44.293029Z","shell.execute_reply":"2026-01-03T01:10:44.307936Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# FCN16s - Skip connection from pool4\nclass FCN16s(nn.Module):\n    def __init__(self, pretrained_net, n_class):\n        super().__init__()\n        self.n_class = n_class\n        self.pretrained_net = pretrained_net\n        self.relu = nn.ReLU(inplace=True)\n        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n        self.bn1 = nn.BatchNorm2d(512)\n        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n        self.bn2 = nn.BatchNorm2d(256)\n        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n        self.bn3 = nn.BatchNorm2d(128)\n        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n        self.bn4 = nn.BatchNorm2d(64)\n        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n        self.bn5 = nn.BatchNorm2d(32)\n        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n\n    def forward(self, x):\n        output = self.pretrained_net(x)\n        x5 = output['x5']  # size=(N, 512, x.H/32, x.W/32)\n        x4 = output['x4']  # size=(N, 512, x.H/16, x.W/16)\n\n        score = self.relu(self.deconv1(x5))               # size=(N, 512, x.H/16, x.W/16)\n        score = self.bn1(score + x4)                      # element-wise add, size=(N, 512, x.H/16, x.W/16)\n        score = self.bn2(self.relu(self.deconv2(score)))  # size=(N, 256, x.H/8, x.W/8)\n        score = self.bn3(self.relu(self.deconv3(score)))  # size=(N, 128, x.H/4, x.W/4)\n        score = self.bn4(self.relu(self.deconv4(score)))  # size=(N, 64, x.H/2, x.W/2)\n        score = self.bn5(self.relu(self.deconv5(score)))  # size=(N, 32, x.H, x.W)\n        score = self.classifier(score)                    # size=(N, n_class, x.H/1, x.W/1)\n\n        return score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T01:10:46.501309Z","iopub.execute_input":"2026-01-03T01:10:46.501614Z","iopub.status.idle":"2026-01-03T01:10:46.509725Z","shell.execute_reply.started":"2026-01-03T01:10:46.501589Z","shell.execute_reply":"2026-01-03T01:10:46.508993Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# FCN8s - Skip connections from pool4 and pool3\nclass FCN8s(nn.Module):\n    def __init__(self, pretrained_net, n_class):\n        super().__init__()\n        self.n_class = n_class\n        self.pretrained_net = pretrained_net\n        self.relu = nn.ReLU(inplace=True)\n        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n        self.bn1 = nn.BatchNorm2d(512)\n        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n        self.bn2 = nn.BatchNorm2d(256)\n        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n        self.bn3 = nn.BatchNorm2d(128)\n        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n        self.bn4 = nn.BatchNorm2d(64)\n        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n        self.bn5 = nn.BatchNorm2d(32)\n        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n\n    def forward(self, x):\n        output = self.pretrained_net(x)\n        x5 = output['x5']  # size=(N, 512, x.H/32, x.W/32)\n        x4 = output['x4']  # size=(N, 512, x.H/16, x.W/16)\n        x3 = output['x3']  # size=(N, 256, x.H/8,  x.W/8)\n\n        score = self.relu(self.deconv1(x5))               # size=(N, 512, x.H/16, x.W/16)\n        score = self.bn1(score + x4)                      # element-wise add, size=(N, 512, x.H/16, x.W/16)\n        score = self.relu(self.deconv2(score))            # size=(N, 256, x.H/8, x.W/8)\n        score = self.bn2(score + x3)                      # element-wise add, size=(N, 256, x.H/8, x.W/8)\n        score = self.bn3(self.relu(self.deconv3(score)))  # size=(N, 128, x.H/4, x.W/4)\n        score = self.bn4(self.relu(self.deconv4(score)))  # size=(N, 64, x.H/2, x.W/2)\n        score = self.bn5(self.relu(self.deconv5(score)))  # size=(N, 32, x.H, x.W)\n        score = self.classifier(score)                    # size=(N, n_class, x.H/1, x.W/1)\n\n        return score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T01:10:51.784099Z","iopub.execute_input":"2026-01-03T01:10:51.784560Z","iopub.status.idle":"2026-01-03T01:10:51.795468Z","shell.execute_reply.started":"2026-01-03T01:10:51.784524Z","shell.execute_reply":"2026-01-03T01:10:51.794549Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# FCNs - Skip connections from all pools\nclass FCNs(nn.Module):\n    def __init__(self, pretrained_net, n_class):\n        super().__init__()\n        self.n_class = n_class\n        self.pretrained_net = pretrained_net\n        self.relu = nn.ReLU(inplace=True)\n        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n        self.bn1 = nn.BatchNorm2d(512)\n        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n        self.bn2 = nn.BatchNorm2d(256)\n        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n        self.bn3 = nn.BatchNorm2d(128)\n        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n        self.bn4 = nn.BatchNorm2d(64)\n        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n        self.bn5 = nn.BatchNorm2d(32)\n        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n\n    def forward(self, x):\n        output = self.pretrained_net(x)\n        x5 = output['x5']  # size=(N, 512, x.H/32, x.W/32)\n        x4 = output['x4']  # size=(N, 512, x.H/16, x.W/16)\n        x3 = output['x3']  # size=(N, 256, x.H/8,  x.W/8)\n        x2 = output['x2']  # size=(N, 128, x.H/4,  x.W/4)\n        x1 = output['x1']  # size=(N, 64, x.H/2,  x.W/2)\n\n        score = self.bn1(self.relu(self.deconv1(x5)))     # size=(N, 512, x.H/16, x.W/16)\n        score = score + x4                                # element-wise add\n        score = self.bn2(self.relu(self.deconv2(score)))  # size=(N, 256, x.H/8, x.W/8)\n        score = score + x3                                # element-wise add\n        score = self.bn3(self.relu(self.deconv3(score)))  # size=(N, 128, x.H/4, x.W/4)\n        score = score + x2                                # element-wise add\n        score = self.bn4(self.relu(self.deconv4(score)))  # size=(N, 64, x.H/2, x.W/2)\n        score = score + x1                                # element-wise add\n        score = self.bn5(self.relu(self.deconv5(score)))  # size=(N, 32, x.H, x.W)\n        score = self.classifier(score)                    # size=(N, n_class, x.H/1, x.W/1)\n\n        return score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T01:10:55.173309Z","iopub.execute_input":"2026-01-03T01:10:55.173626Z","iopub.status.idle":"2026-01-03T01:10:55.182067Z","shell.execute_reply.started":"2026-01-03T01:10:55.173599Z","shell.execute_reply":"2026-01-03T01:10:55.181437Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Transforms dataset","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms\n\nimage_transform = transforms.Compose([\n    transforms.Resize((224, 224)),          # FCN expects fixed size\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T01:10:57.211566Z","iopub.execute_input":"2026-01-03T01:10:57.212072Z","iopub.status.idle":"2026-01-03T01:10:57.216266Z","shell.execute_reply.started":"2026-01-03T01:10:57.212045Z","shell.execute_reply":"2026-01-03T01:10:57.215545Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"mask_transform = transforms.Compose([\n    transforms.Resize((224, 224), interpolation=Image.NEAREST),\n    transforms.Lambda(lambda x: torch.from_numpy(np.array(x)).long())\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T01:10:59.325438Z","iopub.execute_input":"2026-01-03T01:10:59.326129Z","iopub.status.idle":"2026-01-03T01:10:59.329660Z","shell.execute_reply.started":"2026-01-03T01:10:59.326102Z","shell.execute_reply":"2026-01-03T01:10:59.329027Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"VOC_ROOT = \"/kaggle/input/pascal-voc-2012-dataset/VOC2012_train_val/VOC2012_train_val\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T01:11:01.739568Z","iopub.execute_input":"2026-01-03T01:11:01.739859Z","iopub.status.idle":"2026-01-03T01:11:01.743520Z","shell.execute_reply.started":"2026-01-03T01:11:01.739834Z","shell.execute_reply":"2026-01-03T01:11:01.742793Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## Dataset and DataLoader","metadata":{}},{"cell_type":"code","source":"train_dataset = VOCSegmentation(\n    root=VOC_ROOT,\n    split='train',\n    transform=image_transform,\n    target_transform=mask_transform\n)\n\nval_dataset = VOCSegmentation(\n    root=VOC_ROOT,\n    split='val',\n    transform=image_transform,\n    target_transform=mask_transform\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T01:11:03.416587Z","iopub.execute_input":"2026-01-03T01:11:03.416885Z","iopub.status.idle":"2026-01-03T01:11:03.459213Z","shell.execute_reply.started":"2026-01-03T01:11:03.416858Z","shell.execute_reply":"2026-01-03T01:11:03.458553Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=4,\n    shuffle=True,\n    num_workers=4,\n    pin_memory=True\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=4,\n    shuffle=False,\n    num_workers=4,\n    pin_memory=True\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T01:11:05.693415Z","iopub.execute_input":"2026-01-03T01:11:05.693997Z","iopub.status.idle":"2026-01-03T01:11:05.698045Z","shell.execute_reply.started":"2026-01-03T01:11:05.693968Z","shell.execute_reply":"2026-01-03T01:11:05.697382Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"img, mask = train_dataset[0]\nprint(img.shape)     # (3, 224, 224)\nprint(mask.shape)    # (224, 224)\nprint(torch.unique(mask))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T01:11:07.583378Z","iopub.execute_input":"2026-01-03T01:11:07.584036Z","iopub.status.idle":"2026-01-03T01:11:07.707843Z","shell.execute_reply.started":"2026-01-03T01:11:07.584005Z","shell.execute_reply":"2026-01-03T01:11:07.707177Z"}},"outputs":[{"name":"stdout","text":"torch.Size([3, 224, 224])\ntorch.Size([224, 224])\ntensor([  0,   1,  15, 255])\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## Training Loops","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef train_epoch(model, dataloader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n\n    for images, masks in tqdm(dataloader, desc='Training'):\n        images = images.to(device)\n        masks = masks.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)            # (N, C, H, W)\n        loss = criterion(outputs, masks)  # ignore_index=255 handles void\n\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    return running_loss / len(dataloader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T01:11:10.524933Z","iopub.execute_input":"2026-01-03T01:11:10.525642Z","iopub.status.idle":"2026-01-03T01:11:10.530138Z","shell.execute_reply.started":"2026-01-03T01:11:10.525613Z","shell.execute_reply":"2026-01-03T01:11:10.529528Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"@torch.no_grad()\ndef validate_epoch(model, dataloader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n\n    for images, masks in tqdm(dataloader, desc='Validation'):\n        images = images.to(device)\n        masks = masks.to(device)\n\n        outputs = model(images)\n        loss = criterion(outputs, masks)\n\n        running_loss += loss.item()\n\n    return running_loss / len(dataloader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T01:11:12.215409Z","iopub.execute_input":"2026-01-03T01:11:12.216248Z","iopub.status.idle":"2026-01-03T01:11:12.220792Z","shell.execute_reply.started":"2026-01-03T01:11:12.216218Z","shell.execute_reply":"2026-01-03T01:11:12.220021Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"## IoU","metadata":{}},{"cell_type":"code","source":"def fast_hist(pred, label, n_class):\n    mask = (label >= 0) & (label < n_class)\n    return torch.bincount(\n        n_class * label[mask] + pred[mask],\n        minlength=n_class ** 2\n    ).reshape(n_class, n_class)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T01:11:14.119314Z","iopub.execute_input":"2026-01-03T01:11:14.119644Z","iopub.status.idle":"2026-01-03T01:11:14.123953Z","shell.execute_reply.started":"2026-01-03T01:11:14.119616Z","shell.execute_reply":"2026-01-03T01:11:14.123214Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"@torch.no_grad()\ndef evaluate_iou(model, dataloader, device, num_classes):\n    model.eval()\n    hist = torch.zeros((num_classes, num_classes), device=device)\n\n    for images, masks in tqdm(dataloader, desc='Evaluating IoU'):\n        images = images.to(device)\n        masks = masks.to(device)\n\n        outputs = model(images)\n        preds = torch.argmax(outputs, dim=1)\n\n        valid = masks != 255\n        hist += fast_hist(\n            preds[valid],\n            masks[valid],\n            num_classes\n        )\n\n    iou = torch.diag(hist) / (\n        hist.sum(1) + hist.sum(0) - torch.diag(hist) + 1e-10\n    )\n\n    mean_iou = torch.nanmean(iou).item()\n    return iou.cpu().numpy(), mean_iou\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T01:11:16.108871Z","iopub.execute_input":"2026-01-03T01:11:16.109572Z","iopub.status.idle":"2026-01-03T01:11:16.114726Z","shell.execute_reply.started":"2026-01-03T01:11:16.109536Z","shell.execute_reply":"2026-01-03T01:11:16.113960Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"    # Hyperparameters\n    BATCH_SIZE = 4\n    LEARNING_RATE = 1e-4\n    NUM_EPOCHS = 50\n    NUM_CLASSES = 21\n    MODEL_TYPE = 'fcn8s'  # 'fcn32s', 'fcn16s', 'fcn8s', or 'fcns'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T01:11:17.952880Z","iopub.execute_input":"2026-01-03T01:11:17.953198Z","iopub.status.idle":"2026-01-03T01:11:17.957216Z","shell.execute_reply.started":"2026-01-03T01:11:17.953169Z","shell.execute_reply":"2026-01-03T01:11:17.956577Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"    # Device\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f'Using device: {device}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T01:11:19.852608Z","iopub.execute_input":"2026-01-03T01:11:19.852889Z","iopub.status.idle":"2026-01-03T01:11:19.938488Z","shell.execute_reply.started":"2026-01-03T01:11:19.852865Z","shell.execute_reply":"2026-01-03T01:11:19.937783Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Create VGGNet backbone\nvgg_model = VGGNet(pretrained=True, model='vgg16', requires_grad=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T01:11:21.424397Z","iopub.execute_input":"2026-01-03T01:11:21.425114Z","iopub.status.idle":"2026-01-03T01:11:27.692675Z","shell.execute_reply.started":"2026-01-03T01:11:21.425086Z","shell.execute_reply":"2026-01-03T01:11:27.691880Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 528M/528M [00:02<00:00, 195MB/s] \n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Create FCN model\nmodel_dict = {\n    'fcn32s': FCN32s,\n    'fcn16s': FCN16s,\n    'fcn8s': FCN8s,\n    'fcns': FCNs\n}\n\nmodel = model_dict[MODEL_TYPE](pretrained_net=vgg_model, n_class=NUM_CLASSES).to(device)\nprint(f'\\nUsing {MODEL_TYPE.upper()} architecture')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T01:11:33.872090Z","iopub.execute_input":"2026-01-03T01:11:33.872394Z","iopub.status.idle":"2026-01-03T01:11:34.127686Z","shell.execute_reply.started":"2026-01-03T01:11:33.872367Z","shell.execute_reply":"2026-01-03T01:11:34.127072Z"}},"outputs":[{"name":"stdout","text":"\nUsing FCN8S architecture\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Loss and optimizer\ncriterion = nn.CrossEntropyLoss(ignore_index=255)\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T01:11:36.572778Z","iopub.execute_input":"2026-01-03T01:11:36.573236Z","iopub.status.idle":"2026-01-03T01:11:36.577688Z","shell.execute_reply.started":"2026-01-03T01:11:36.573208Z","shell.execute_reply":"2026-01-03T01:11:36.576893Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"best_miou = 0.0\nNUM_EPOCHS = 50\n\nfor epoch in range(NUM_EPOCHS):\n    print(f'\\n{\"=\"*60}')\n    print(f'Epoch {epoch+1}/{NUM_EPOCHS}')\n    print(f'{\"=\"*60}')\n\n    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n    val_loss = validate_epoch(model, val_loader, criterion, device)\n\n    print(f'Train Loss: {train_loss:.4f}')\n    print(f'Val   Loss: {val_loss:.4f}')\n\n    if (epoch + 1) % 5 == 0:\n        print('\\nEvaluating mIoU...')\n        ious, mean_iou = evaluate_iou(model, val_loader, device, NUM_CLASSES)\n        print(f'Mean IoU: {mean_iou*100:.2f}%')\n\n        voc_classes = [\n            'background', 'aeroplane', 'bicycle', 'bird', 'boat',\n            'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n            'diningtable', 'dog', 'horse', 'motorbike', 'person',\n            'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'\n        ]\n\n        print('\\nPer-class IoU:')\n        for cls, iou in zip(voc_classes, ious):\n            print(f'{cls:15s}: {iou*100:5.2f}%')\n\n        if mean_iou > best_miou:\n            best_miou = mean_iou\n            torch.save(model.state_dict(), f'fcn_{MODEL_TYPE}_best.pth')\n            print(f'✓ Model saved! Best mIoU: {best_miou*100:.2f}%')\n\n    scheduler.step()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T01:11:42.002075Z","iopub.execute_input":"2026-01-03T01:11:42.002390Z","iopub.status.idle":"2026-01-03T01:53:49.359822Z","shell.execute_reply.started":"2026-01-03T01:11:42.002350Z","shell.execute_reply":"2026-01-03T01:53:49.359081Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nEpoch 1/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:33<00:00, 10.84it/s]\nValidation: 100%|██████████| 363/363 [00:11<00:00, 31.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 2.4259\nVal   Loss: 1.9698\n\n============================================================\nEpoch 2/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:33<00:00, 11.01it/s]\nValidation: 100%|██████████| 363/363 [00:11<00:00, 30.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.7582\nVal   Loss: 1.5420\n\n============================================================\nEpoch 3/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:33<00:00, 10.82it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 29.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.3979\nVal   Loss: 1.2585\n\n============================================================\nEpoch 4/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:34<00:00, 10.66it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 29.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.1594\nVal   Loss: 1.2603\n\n============================================================\nEpoch 5/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:34<00:00, 10.52it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 29.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.0443\nVal   Loss: 1.0086\n\nEvaluating mIoU...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating IoU: 100%|██████████| 363/363 [00:12<00:00, 28.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Mean IoU: 9.84%\n\nPer-class IoU:\nbackground     : 86.00%\naeroplane      :  1.68%\nbicycle        :  0.01%\nbird           :  0.34%\nboat           :  0.00%\nbottle         :  0.00%\nbus            : 17.31%\ncar            :  7.50%\ncat            : 28.60%\nchair          :  0.59%\ncow            :  0.03%\ndiningtable    :  0.01%\ndog            :  0.18%\nhorse          :  0.39%\nmotorbike      :  3.94%\nperson         : 54.36%\npottedplant    :  0.00%\nsheep          :  0.01%\nsofa           :  0.00%\ntrain          :  4.77%\ntvmonitor      :  1.01%\n✓ Model saved! Best mIoU: 9.84%\n\n============================================================\nEpoch 6/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.39it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.9450\nVal   Loss: 1.1215\n\n============================================================\nEpoch 7/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.37it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8506\nVal   Loss: 0.9186\n\n============================================================\nEpoch 8/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.34it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7781\nVal   Loss: 0.9257\n\n============================================================\nEpoch 9/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.31it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7219\nVal   Loss: 0.8788\n\n============================================================\nEpoch 10/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.29it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.6652\nVal   Loss: 0.9499\n\nEvaluating mIoU...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating IoU: 100%|██████████| 363/363 [00:12<00:00, 28.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Mean IoU: 14.63%\n\nPer-class IoU:\nbackground     : 88.02%\naeroplane      :  7.37%\nbicycle        :  0.01%\nbird           :  6.80%\nboat           :  1.86%\nbottle         :  0.00%\nbus            : 32.53%\ncar            : 28.69%\ncat            : 31.67%\nchair          :  1.17%\ncow            :  0.14%\ndiningtable    :  8.41%\ndog            :  4.31%\nhorse          :  2.19%\nmotorbike      : 14.62%\nperson         : 58.64%\npottedplant    :  0.08%\nsheep          :  2.32%\nsofa           :  0.57%\ntrain          :  4.96%\ntvmonitor      : 12.78%\n✓ Model saved! Best mIoU: 14.63%\n\n============================================================\nEpoch 11/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.30it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.6243\nVal   Loss: 0.9320\n\n============================================================\nEpoch 12/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.29it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.5666\nVal   Loss: 0.8662\n\n============================================================\nEpoch 13/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.27it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.5109\nVal   Loss: 0.7913\n\n============================================================\nEpoch 14/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.29it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4686\nVal   Loss: 0.8065\n\n============================================================\nEpoch 15/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.30it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4183\nVal   Loss: 0.7754\n\nEvaluating mIoU...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating IoU: 100%|██████████| 363/363 [00:12<00:00, 28.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Mean IoU: 24.30%\n\nPer-class IoU:\nbackground     : 88.55%\naeroplane      : 37.18%\nbicycle        :  0.00%\nbird           : 27.20%\nboat           : 11.63%\nbottle         :  0.05%\nbus            : 41.01%\ncar            : 37.95%\ncat            : 40.79%\nchair          :  8.87%\ncow            :  1.46%\ndiningtable    : 20.02%\ndog            : 12.77%\nhorse          :  8.22%\nmotorbike      : 32.04%\nperson         : 60.16%\npottedplant    :  2.56%\nsheep          : 21.34%\nsofa           : 14.15%\ntrain          : 12.18%\ntvmonitor      : 32.14%\n✓ Model saved! Best mIoU: 24.30%\n\n============================================================\nEpoch 16/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.28it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4211\nVal   Loss: 0.7843\n\n============================================================\nEpoch 17/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.28it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3581\nVal   Loss: 0.7478\n\n============================================================\nEpoch 18/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.29it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3096\nVal   Loss: 0.7298\n\n============================================================\nEpoch 19/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.30it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2653\nVal   Loss: 0.7312\n\n============================================================\nEpoch 20/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.27it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2246\nVal   Loss: 0.7299\n\nEvaluating mIoU...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating IoU: 100%|██████████| 363/363 [00:12<00:00, 28.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Mean IoU: 34.21%\n\nPer-class IoU:\nbackground     : 88.47%\naeroplane      : 58.47%\nbicycle        :  0.00%\nbird           : 17.89%\nboat           : 27.81%\nbottle         : 23.63%\nbus            : 55.53%\ncar            : 52.56%\ncat            : 40.66%\nchair          :  7.24%\ncow            : 24.03%\ndiningtable    : 20.38%\ndog            : 35.14%\nhorse          : 18.76%\nmotorbike      : 37.83%\nperson         : 63.87%\npottedplant    : 20.17%\nsheep          : 30.68%\nsofa           : 16.19%\ntrain          : 38.49%\ntvmonitor      : 40.65%\n✓ Model saved! Best mIoU: 34.21%\n\n============================================================\nEpoch 21/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.29it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1879\nVal   Loss: 0.7077\n\n============================================================\nEpoch 22/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.28it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1532\nVal   Loss: 0.7092\n\n============================================================\nEpoch 23/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.29it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1334\nVal   Loss: 0.7040\n\n============================================================\nEpoch 24/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.28it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1242\nVal   Loss: 0.6979\n\n============================================================\nEpoch 25/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.28it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1131\nVal   Loss: 0.7321\n\nEvaluating mIoU...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating IoU: 100%|██████████| 363/363 [00:12<00:00, 28.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Mean IoU: 37.90%\n\nPer-class IoU:\nbackground     : 88.58%\naeroplane      : 61.79%\nbicycle        :  5.75%\nbird           : 28.58%\nboat           : 30.27%\nbottle         : 26.65%\nbus            : 55.21%\ncar            : 53.34%\ncat            : 51.36%\nchair          : 10.15%\ncow            : 28.43%\ndiningtable    : 18.19%\ndog            : 39.11%\nhorse          : 28.39%\nmotorbike      : 45.09%\nperson         : 64.78%\npottedplant    : 19.88%\nsheep          : 40.55%\nsofa           : 17.07%\ntrain          : 42.34%\ntvmonitor      : 40.34%\n✓ Model saved! Best mIoU: 37.90%\n\n============================================================\nEpoch 26/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.28it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1047\nVal   Loss: 0.7468\n\n============================================================\nEpoch 27/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.31it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0991\nVal   Loss: 0.8080\n\n============================================================\nEpoch 28/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.31it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1128\nVal   Loss: 0.8158\n\n============================================================\nEpoch 29/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.29it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0966\nVal   Loss: 0.7475\n\n============================================================\nEpoch 30/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.28it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0737\nVal   Loss: 0.7424\n\nEvaluating mIoU...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating IoU: 100%|██████████| 363/363 [00:12<00:00, 28.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Mean IoU: 39.21%\n\nPer-class IoU:\nbackground     : 88.60%\naeroplane      : 61.19%\nbicycle        : 27.37%\nbird           : 31.56%\nboat           : 27.72%\nbottle         : 29.26%\nbus            : 54.36%\ncar            : 45.02%\ncat            : 50.99%\nchair          :  9.80%\ncow            : 30.86%\ndiningtable    : 21.44%\ndog            : 39.66%\nhorse          : 26.66%\nmotorbike      : 47.45%\nperson         : 65.74%\npottedplant    : 22.11%\nsheep          : 41.93%\nsofa           : 19.70%\ntrain          : 39.24%\ntvmonitor      : 42.82%\n✓ Model saved! Best mIoU: 39.21%\n\n============================================================\nEpoch 31/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.27it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0667\nVal   Loss: 0.7567\n\n============================================================\nEpoch 32/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.31it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0604\nVal   Loss: 0.7577\n\n============================================================\nEpoch 33/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.30it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0571\nVal   Loss: 0.7813\n\n============================================================\nEpoch 34/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.31it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0564\nVal   Loss: 0.7367\n\n============================================================\nEpoch 35/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.30it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0653\nVal   Loss: 0.8088\n\nEvaluating mIoU...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating IoU: 100%|██████████| 363/363 [00:12<00:00, 28.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Mean IoU: 36.91%\n\nPer-class IoU:\nbackground     : 88.28%\naeroplane      : 60.76%\nbicycle        : 28.21%\nbird           : 26.13%\nboat           : 27.62%\nbottle         : 26.95%\nbus            : 54.66%\ncar            : 51.46%\ncat            : 39.39%\nchair          : 12.38%\ncow            : 16.79%\ndiningtable    : 20.62%\ndog            : 39.09%\nhorse          : 24.05%\nmotorbike      : 43.61%\nperson         : 64.20%\npottedplant    : 19.38%\nsheep          : 36.59%\nsofa           : 12.40%\ntrain          : 41.77%\ntvmonitor      : 40.82%\n\n============================================================\nEpoch 36/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.28it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0720\nVal   Loss: 0.7797\n\n============================================================\nEpoch 37/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.30it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0469\nVal   Loss: 0.8001\n\n============================================================\nEpoch 38/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.31it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0382\nVal   Loss: 0.7675\n\n============================================================\nEpoch 39/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.30it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0392\nVal   Loss: 0.8019\n\n============================================================\nEpoch 40/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.31it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0373\nVal   Loss: 0.8084\n\nEvaluating mIoU...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating IoU: 100%|██████████| 363/363 [00:12<00:00, 28.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Mean IoU: 40.89%\n\nPer-class IoU:\nbackground     : 88.78%\naeroplane      : 63.77%\nbicycle        : 34.16%\nbird           : 31.59%\nboat           : 34.09%\nbottle         : 32.14%\nbus            : 57.99%\ncar            : 55.30%\ncat            : 45.65%\nchair          : 11.94%\ncow            : 29.24%\ndiningtable    : 21.57%\ndog            : 37.67%\nhorse          : 28.49%\nmotorbike      : 48.56%\nperson         : 65.47%\npottedplant    : 26.45%\nsheep          : 39.17%\nsofa           : 17.48%\ntrain          : 43.77%\ntvmonitor      : 45.47%\n✓ Model saved! Best mIoU: 40.89%\n\n============================================================\nEpoch 41/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.28it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0316\nVal   Loss: 0.8245\n\n============================================================\nEpoch 42/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.30it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0288\nVal   Loss: 0.8273\n\n============================================================\nEpoch 43/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.29it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0283\nVal   Loss: 0.8322\n\n============================================================\nEpoch 44/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.30it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0258\nVal   Loss: 0.8701\n\n============================================================\nEpoch 45/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.31it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0243\nVal   Loss: 0.8255\n\nEvaluating mIoU...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating IoU: 100%|██████████| 363/363 [00:12<00:00, 28.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Mean IoU: 41.36%\n\nPer-class IoU:\nbackground     : 88.83%\naeroplane      : 63.20%\nbicycle        : 27.25%\nbird           : 37.26%\nboat           : 34.28%\nbottle         : 30.84%\nbus            : 58.12%\ncar            : 56.40%\ncat            : 52.07%\nchair          : 12.35%\ncow            : 24.89%\ndiningtable    : 24.32%\ndog            : 40.21%\nhorse          : 29.82%\nmotorbike      : 45.67%\nperson         : 65.19%\npottedplant    : 24.25%\nsheep          : 44.76%\nsofa           : 18.02%\ntrain          : 44.38%\ntvmonitor      : 46.35%\n✓ Model saved! Best mIoU: 41.36%\n\n============================================================\nEpoch 46/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.28it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0235\nVal   Loss: 0.8524\n\n============================================================\nEpoch 47/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.28it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0240\nVal   Loss: 0.8418\n\n============================================================\nEpoch 48/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.29it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0218\nVal   Loss: 0.8544\n\n============================================================\nEpoch 49/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.30it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0218\nVal   Loss: 0.8991\n\n============================================================\nEpoch 50/50\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 366/366 [00:35<00:00, 10.30it/s]\nValidation: 100%|██████████| 363/363 [00:12<00:00, 28.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0208\nVal   Loss: 0.8420\n\nEvaluating mIoU...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating IoU: 100%|██████████| 363/363 [00:12<00:00, 28.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Mean IoU: 41.43%\n\nPer-class IoU:\nbackground     : 88.81%\naeroplane      : 62.28%\nbicycle        : 29.98%\nbird           : 37.50%\nboat           : 33.08%\nbottle         : 32.29%\nbus            : 57.63%\ncar            : 56.13%\ncat            : 51.68%\nchair          : 13.28%\ncow            : 28.17%\ndiningtable    : 24.73%\ndog            : 40.29%\nhorse          : 29.62%\nmotorbike      : 48.12%\nperson         : 65.04%\npottedplant    : 26.27%\nsheep          : 38.25%\nsofa           : 17.27%\ntrain          : 43.80%\ntvmonitor      : 45.75%\n✓ Model saved! Best mIoU: 41.43%\n","output_type":"stream"}],"execution_count":29}]}